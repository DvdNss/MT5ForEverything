{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT5ForEverything",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoTIIyZs7emA"
      },
      "source": [
        "# __Init__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C979O2YojuE"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwD5TToH5QLU"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFclFuwt5yEM"
      },
      "source": [
        "!git clone https://dvdnss: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@github.com/DvdNss/MT5ForEverything.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPAYz32c7I0u",
        "outputId": "581638b3-bcb9-44ac-8714-8a249de7019c"
      },
      "source": [
        "%cd MT5ForEverything/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/MT5ForEverything\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgDxcPuw8Zyf"
      },
      "source": [
        "# __Install__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5NTh-la8sRd",
        "outputId": "b2918f92-7b2f-40fe-f596-79959b7a228d"
      },
      "source": [
        "%cd /content/drive/MyDrive/MT5ForEverything/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MT5ForEverything\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvkjZIGo7zN0",
        "outputId": "35835d65-4958-4c4f-eb17-17d7461c2f33"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvqvV6Fs8dml",
        "outputId": "d88142a6-cc07-4603-b6ea-960eab1d9a87"
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'torch~=1.10.0+cu113' (from line 7 of requirements.txt)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL46xUHx7mxk"
      },
      "source": [
        "# __Running__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Xw6yyQ7XyM"
      },
      "source": [
        "from source import databuilder \n",
        "\n",
        "databuilder_args = dict(\n",
        "   source_max_length=512,  # Maximum length of source text\n",
        "   target_max_length=30,  # Maximum length of target text\n",
        "   tokenizer_name_or_path='google/mt5-small',  # Tokenizer path\n",
        "   tokenizer_save_path='model/tokenizer',  # Tokenizer save path\n",
        "   train_csv_path='data/train.tsv',  # Training file path\n",
        "   valid_csv_path='data/valid.tsv',  # Validation file path\n",
        "   source_column='source_text',  # Source column\n",
        "   target_column='target_text',  # Target column\n",
        "   train_data_save_path='data/train.pt',  # Training data save path\n",
        "   valid_data_save_path='data/valid.pt',  # Validation data save path\n",
        "   databuilder_config_save_path='model/config/config.json'  # Save path of databuilder config\n",
        ")\n",
        "\n",
        "# Running databuilder\n",
        "databuilder.run(args_dict=databuilder_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75WOvLw_75kT"
      },
      "source": [
        "from source import train\n",
        "\n",
        "train_args = dict(\n",
        "   output_dir=\"model\",  # output directory of model & tokenizer\n",
        "   model_config_save_path=\"model/config/config.json\",  # output path of model config\n",
        "   wandb_project_name='mt5-project',  # wandb project name for training tracking\n",
        "   overwrite_output_dir=True,  # whether to overwrite output_dir or not\n",
        "   do_train=True,  # whether to train or not\n",
        "   do_eval=True,  # whether to evaluate or not\n",
        "   seed=42,  # seed to use\n",
        "   learning_rate=1e-4,  # learning rate\n",
        "   num_train_epochs=1,  # number of epochs\n",
        "   per_device_train_batch_size=1,  # train batch size\n",
        "   per_device_eval_batch_size=1,  # eval batch size\n",
        "   evaluation_strategy=\"epoch\"  # evaluation strategy\n",
        ")\n",
        "\n",
        "# Starting training\n",
        "train.run(args_dict=train_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDvV00Q7-RK",
        "outputId": "5ad4f3e6-088e-4c3f-e1ff-beabc811abc5"
      },
      "source": [
        "from source import pipelines\n",
        "\n",
        "pipeline_args = dict(\n",
        "   pipeline='classic',\n",
        "   pipeline_config_path='model/config/classic.json'\n",
        ")\n",
        "\n",
        "# Loading the pipeline\n",
        "pipeline = pipelines.run(args_dict=pipeline_args)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11/17/2021 03:48:59 - INFO - source.pipelines -   Pipeline has been loaded and is ready for inference. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_vGNn5u-c3x",
        "outputId": "70d3b413-d206-4cdf-c67c-f32fbd3e6cca"
      },
      "source": [
        "# Inference\n",
        "inference = pipeline(inputs='Where are my grades ?')\n",
        "print(inference)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<extra_id_0>\n"
          ]
        }
      ]
    }
  ]
}